{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 21:51:29.782910: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch-local/slurm-job-tmp-194105/ipykernel_133/4090635601.py:26: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "using gpu:0 device \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 21:51:42.083044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /device:GPU:0 with 4486 MB memory:  -> device: 0, name: Quadro P2000, pci bus id: 0000:61:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import random\n",
    "import math as m\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import sys\n",
    "\n",
    "parent_directory = '/project/ag-seitz/users/sijin/master_thesis/MCMC/affine'\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "from affine.affine.affine import *\n",
    "# from scipy import interpolate\n",
    "# from cosmopower import cosmopower_NN\n",
    "\n",
    "\n",
    "# checking that we are using a GPU\n",
    "device = 'gpu:0' if tf.test.is_gpu_available() else 'cpu'\n",
    "print('using', device, 'device \\n')\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    }
   ],
   "source": [
    "data_np = np.loadtxt(\"/home/s/Sijin.Chen/course/from_data_to_insights/tutorial08/xi_measurement_tutorial8.dat\")\n",
    "print(data_np.shape)\n",
    "theta_np = data_np[:, 0]\n",
    "xi_np = data_np[:, 1]\n",
    "err_np = data_np[:, 2]\n",
    "err_cov_np = np.diag(err_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-15 21:51:42.715201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4486 MB memory:  -> device: 0, name: Quadro P2000, pci bus id: 0000:61:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "theta_tf = tf.convert_to_tensor(theta_np)\n",
    "xi_tf = tf.convert_to_tensor(xi_np)\n",
    "err_tf = tf.convert_to_tensor(err_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target log prior\n",
    "@tf.function\n",
    "def log_prior(params):\n",
    "    A, B, alpha_B = params\n",
    "    if -10.0 <= A <= 10.0 and -10.0 <= B <= 10.0 and 0.0 <= alpha_B <=0.4 :\n",
    "        return 0.0\n",
    "    return -np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target log likelihood\n",
    "@tf.function\n",
    "def log_likelihood(params, theta, xi, err_cov):\n",
    "    A, B, alpha_B = params\n",
    "    xi_model = A*theta **0.5 + B*theta **alpha_B\n",
    "    diff = xi_model - xi      \n",
    "    result = -0.5 * diff.T @ np.linalg.inv(err_cov) @ diff \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(params, theta, xi, err_cov):\n",
    "    \n",
    "    A, B, alpha_B = params\n",
    "    lp = log_prior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(params, theta, xi, err_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m current_state \u001b[38;5;241m=\u001b[39m [walkers1, walkers2]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#chain, logp_chain = affine.affine_sample(log_posterior, total_steps, current_state, args=[])\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     chain \u001b[38;5;241m=\u001b[39m \u001b[43maffine_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_posterior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtheta_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_cov_np\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/course/from_data_to_insights/tutorial08/affine/affine/affine.py:14\u001b[0m, in \u001b[0;36maffine_sample\u001b[0;34m(log_prob, n_steps, current_state, args, progressbar)\u001b[0m\n\u001b[1;32m     11\u001b[0m n_walkers, n_params \u001b[38;5;241m=\u001b[39m current_state1\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# initial target log prob for the walkers (and set any nans to -inf)...\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m logp_current1 \u001b[38;5;241m=\u001b[39m \u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_state1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m logp_current2 \u001b[38;5;241m=\u001b[39m log_prob(current_state2, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     16\u001b[0m logp_current1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mwhere(tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mis_nan(logp_current1), tf\u001b[38;5;241m.\u001b[39mones_like(logp_current1)\u001b[38;5;241m*\u001b[39mtf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m0.\u001b[39m), logp_current1)\n",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m, in \u001b[0;36mlog_posterior\u001b[0;34m(params, theta, xi, err_cov)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_posterior\u001b[39m(params, theta, xi, err_cov):\n\u001b[0;32m----> 3\u001b[0m     A, B, alpha_B \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m      4\u001b[0m     lp \u001b[38;5;241m=\u001b[39m log_prior(params)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(lp):\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# run the sampler\n",
    "total_steps = 5000\n",
    "nwalkers = 500\n",
    "ndim = 3\n",
    "walkers1 = tf.random.normal([nwalkers, 3], 0., 1.)\n",
    "walkers2 = tf.random.normal([nwalkers, 3], 0., 1.)\n",
    "current_state = [walkers1, walkers2]\n",
    "\n",
    "\n",
    "\n",
    "with tf.device(device):\n",
    "    #chain, logp_chain = affine.affine_sample(log_posterior, total_steps, current_state, args=[])\n",
    "    chain = affine_sample(log_posterior, total_steps, current_state, args=[theta_np, xi_np, err_cov_np])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def log_posterior(params, data, inv_cov):\n",
    "    \n",
    "#     lp = log_prior(params, params.shape[0])\n",
    "#     posterior = -np.inf * tf.ones(params.shape[0])\n",
    "    \n",
    "#     mask = tf.math.is_finite(lp)\n",
    "#     indices = tf.where(mask)\n",
    "#     likelihood = log_likelihood(params[mask], data, inv_cov)\n",
    "    \n",
    "#     posterior = tf.tensor_scatter_nd_update(posterior, indices, tf.add(likelihood, lp[mask]))\n",
    "#     return posterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
